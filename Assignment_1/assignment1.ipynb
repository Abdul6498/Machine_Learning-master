{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: k-nearest neighbors (100 points)\n",
    "\n",
    "Only use the already imported libraries `numpy` and `matplotlib.pyplot` for the assignment. Do not import any other library. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==> *Write*\n",
    "* name: Abdul Rehman\n",
    "* *matr. nr.* 3440146\n",
    "* *study program* M.Sc. INFOTECH\n",
    "* *B.Sc./M.Sc.*\n",
    "\n",
    "*of all assignment group participants here.* (double klick here to edit)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178\n",
      "178\n"
     ]
    }
   ],
   "source": [
    "# Load required packages and dataset. Do not modify.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_wine_dataset():\n",
    "    from sklearn import datasets\n",
    "    wine = datasets.load_wine()\n",
    "    X = wine.data\n",
    "    y = wine.target\n",
    "    return X, y\n",
    "    \n",
    "X, y = load_wine_dataset()\n",
    "print(len(X))\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Visualization and Preprocessing (25 points)\n",
    "\n",
    "1) *(5 Points)* Explain the content of the dataset in few words. What are the input features? What is the classification target? Check out: [http://archive.ics.uci.edu/ml/datasets/Wine).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has to classify type of wine derived from three different cultivars. It can be analysed by quantities of 13 different constituents as input attributes.\n",
    "\n",
    "    1) Alcohol\n",
    " \t2) Malic acid\n",
    " \t3) Ash\n",
    "\t4) Alcalinity of ash  \n",
    " \t5) Magnesium\n",
    "\t6) Total phenols\n",
    " \t7) Flavanoids\n",
    " \t8) Nonflavanoid phenols\n",
    " \t9) Proanthocyanins\n",
    "\t10)Color intensity\n",
    " \t11)Hue\n",
    " \t12)OD280/OD315 of diluted wines\n",
    " \t13)Proline \n",
    "    \n",
    "  Classification target : Wine of class {'0','1','2'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) *(5 Points)* Compute and print the following statistics about the dataset:\n",
    "  - Number of samples\n",
    "  - Number of samples per class\n",
    "  - Mean and standard deviation for each input feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your solution here.\n",
    "number_of_samples = y.shape[0]\n",
    "print('Number of samples {}'.format(number_of_samples))\n",
    "\n",
    "#number of samples per class\n",
    "unique_elements, counts_elements = np.unique(y, return_counts=True)\n",
    "for i in range(len(unique_elements)):\n",
    "    print('Class {} Samples {}'.format(unique_elements[i], counts_elements[i]))\n",
    "\n",
    "# Mean and std\n",
    "\n",
    "mean = np.mean(input_features, axis = 0)\n",
    "std = np.std(input_features, axis = 0)\n",
    "\n",
    "features = [\"Alcohol\", \"Malic acid\", \"Ash\", \"Alcalinity of ash \", \"Magnesium\", \"Total phenols\", \"Flavanoids\",\"Nonflavanoid phenols\",\"Proanthocyanins\",\"Color intensity\",\"Hue\",\"OD280/OD315 of diluted wines\",\"Proline\"]\n",
    "for i in range(len(features)):\n",
    "    print(\"Feature {}:\".format(features[i]))\n",
    "    print(\"mean: {:.3f}  std: {:.3f} \".format(mean[i], std[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) *(5 Points)* Visualize the variables *alcohol* and *magnesium* in a scatter plot (*alcohol* on the x-axis, *magnesium* on the y-axis). Color each point of the plot according to its class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your solution here.\n",
    "\n",
    "fig = plt.figure()\n",
    "ax=fig.add_axes([0,0,1,1])\n",
    "scatter = ax.scatter(X[:, 0], X[:, 4], c=y, cmap='viridis')\n",
    "ax.set_xlabel('Alcohol')\n",
    "ax.set_ylabel('Magnesium')\n",
    "handles, labels = scatter.legend_elements()\n",
    "labels = ['Class 0', 'Class 1', 'Class 2']\n",
    "ax.legend(handles, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) *(5 Points)* Split the dataset randomly into training and test data. 70% of data should be used for training and 30% should be used for testing. Implement the function `train_test_split`. Do not modify the interface of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-69e786a811e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "def train_test_split(X, y):\n",
    "    \"\"\"\n",
    "    Returns X_train, X_test, y_train, y_test, \n",
    "        where X_train and X_test are the input features of the training and test set,\n",
    "        and y_train and y_test are the class labels of the training and test set.\n",
    "    \"\"\"\n",
    "        shuffled = np.random.permutation(X.shape[0])\n",
    "        split = shuffled < np.percentile(shuffled, 70)\n",
    "        X_train = X[split]\n",
    "        X_test = X[~split]\n",
    "        y_train = y[split]\n",
    "        y_test = y[~split]\n",
    "        \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "assert (X_train.shape[0] + X_test.shape[0]) == X.shape[0]\n",
    "assert (y_train.shape[0] + y_test.shape[0]) == y.shape[0]\n",
    "assert X_train.shape[1] == X_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) *(5 Points)* kNN uses a distance measure to identify close neighbors. If the input features are not of the same scale, the distance is not as meaningful, which can negatively impact classification performance. Perform min-max scaling (i.e. scale the values of the input features in such a way that their range is from 0 to 1) on the training and test data. Remember that you should only use information from the training data to perform the scaling on both data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your solution here\n",
    "# update scaling\n",
    "# normalization formula - https://www.analyticsvidhya.com/blog/2020/04/feature-scaling-machine-learning-normalization-standardization/\n",
    "\n",
    "X_min = np.min(X_train, axis=0)\n",
    "X_max = np.max(X_train, axis=0)\n",
    "X_test = (X_test - X_min) / (X_max - X_min)\n",
    "X_train = (X_train - X_min) / (X_max - X_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: k-nearest neighbors (50 Points)\n",
    "*Choose classes randomly if weights are equal for multiple classes*\n",
    "\n",
    "**For B.Sc. Data Science:**  \n",
    "\n",
    "Implement the kNN algorithm with uniform weighting and arbitrary `k`. Fill out the `predict` method of class `KNearestNeighbors`. \n",
    "\n",
    "Use Euclidean distance to determine the nearest neighbors.\n",
    "You can ignore the optional parameter `weights`, which is provided as a field in the kNN class.\n",
    "\n",
    "**For all students other than B.Sc. Data Science:**\n",
    "\n",
    "Implement the kNN algorithm with uniform and distance-based weighting and arbitrary `k`.\n",
    "Fill out the `predict` method of class `KNearestNeighbors`.\n",
    "\n",
    "The parameter `weights` will either contain the string `uniform` or `distance`. \n",
    "- If the value is `uniform`, the classifier should use the Euclidean distance for determining nearest neighbors and uniform weighting. \n",
    "- If the value is a `distance`, the classifier should use the Euclidean distance for determining neares neighbors and perform distance-weighted classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNearestNeighbors(object):\n",
    "    def __init__(self, k, weights='uniform'):\n",
    "        self.k = k\n",
    "        self.weights = weights\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        This functions saves the training data to be used during the prediction.\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Returns a vector of shape (n,) if X has shape (n,d), \n",
    "        where n is the number of samples and d is the number of features.\n",
    "        \"\"\"\n",
    "        # Implement your solution here.\n",
    "        pass\n",
    "        \n",
    "\n",
    "    \n",
    "def euclidean_distance(x1, x2):\n",
    "    \"\"\"\n",
    "    Given vectors x1 and x2 with shape (n,) returns distance between vectors as float.\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.sum((x1 - x2)*(x1 - x2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Evaluation (25 Points)\n",
    "\n",
    "1) *(10 Points)* Implement functions to compute precision, recall and F1-score. `y_pred` and `y_true` are the vectors of predicted and true class labels respectively with shape `(n,)`, where `n` is the number of samples. Each function should return a float containing the corresponding score. It is advisable to implement a function for the confusion matrix and reuse it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_pred, y_true):\n",
    "    # Implement your solution here.\n",
    "\n",
    "def recall(y_pred, y_true):\n",
    "    # Implement your solution here.\n",
    "\n",
    "def f1score(y_pred, y_true):\n",
    "    # Implement your solution here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) *(10 Points)* Evaluate the performance of kNN with uniform weighting on the Wine dataset for `k=1,5,9`. Train each of the `3` classifiers on the training data from Task 1. Perform the predictions on both the training and test data. Then compute precision, recall, and F1-score for each model and for both training and test data. Visualize the performance in a plot, what do you observe?\n",
    "\n",
    "**For all students other than B.Sc. Data Science:** \n",
    "\n",
    "Also evaluate the kNN classifier with Euclidean distance-weighting. Compare the performance to uniform-weighting. How does the performance change compared to uniform weighting for each `k`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your solution here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==> *Write your observations here and report your results.* (double klick here to edit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) *(5 Points)* Explain why kNN with `k=1` achieves perfect results on the training data. Why is it not the best model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==> *Write your response here.* (double klick here to edit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
